{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "def NemoProcess(nemo_path, output_path, test_split=0.1):\n",
    "    \"\"\"\n",
    "    Process the Nemo dataset into YOLO format with images and labels structured for train, val, and test sets.\n",
    "\n",
    "    Args:\n",
    "        nemo_path (str): Path to the root of the Nemo dataset.\n",
    "        output_path (str): Path where the YOLO formatted dataset will be stored.\n",
    "        test_split (float): Fraction of the data to use as a test set.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Define paths\n",
    "    train_img_path = os.path.join(nemo_path, 'train', 'img')\n",
    "    train_ann_path = os.path.join(nemo_path, 'train', 'ann')\n",
    "    val_img_path = os.path.join(nemo_path, 'val', 'img')\n",
    "    val_ann_path = os.path.join(nemo_path, 'val', 'ann')\n",
    "\n",
    "    # Create YOLO directory structure\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        os.makedirs(os.path.join(output_path, 'images', split), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_path, 'labels', split), exist_ok=True)\n",
    "\n",
    "    # Copy and split the dataset\n",
    "    def process_split(img_path, ann_path, split):\n",
    "        images = glob.glob(os.path.join(img_path, \"*.jpg\"))  # Assuming images are in .jpg format\n",
    "        labels = glob.glob(os.path.join(ann_path, \"*.json\"))\n",
    "\n",
    "        for img_file, label_file in zip(sorted(images), sorted(labels)):\n",
    "            img_name = os.path.basename(img_file)\n",
    "            label_name = os.path.basename(label_file)\n",
    "\n",
    "            shutil.copy(img_file, os.path.join(output_path, 'images', split, img_name))\n",
    "            shutil.copy(label_file, os.path.join(output_path, 'labels', split, label_name))\n",
    "\n",
    "    # Process train and validation sets\n",
    "    process_split(train_img_path, train_ann_path, 'train')\n",
    "    process_split(val_img_path, val_ann_path, 'val')\n",
    "\n",
    "    # Optionally, move a portion of validation to the test set\n",
    "    val_images = os.listdir(os.path.join(output_path, 'images', 'val'))\n",
    "    val_labels = os.listdir(os.path.join(output_path, 'labels', 'val'))\n",
    "    \n",
    "    num_test = int(len(val_images) * test_split)\n",
    "    test_images = val_images[:num_test]\n",
    "    test_labels = val_labels[:num_test]\n",
    "    \n",
    "    for test_img, test_lbl in zip(test_images, test_labels):\n",
    "        shutil.move(os.path.join(output_path, 'images', 'val', test_img), os.path.join(output_path, 'images', 'test', test_img))\n",
    "        shutil.move(os.path.join(output_path, 'labels', 'val', test_lbl), os.path.join(output_path, 'labels', 'test', test_lbl))\n",
    "\n",
    "   \n",
    "    print(f\"YOLO format dataset created at {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2684\n",
      "250\n",
      "YOLO format dataset created at C:\\nico\\wildfire2024\\data\\test\n"
     ]
    }
   ],
   "source": [
    "NemoProcess(\n",
    "    nemo_path=r'C:\\nico\\wildfire2024\\data\\Nemo',\n",
    "    output_path=r'C:\\nico\\wildfire2024\\data\\test',\n",
    "    test_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import json\n",
    "\n",
    "def process_labels_nemo(json_path, txt_output_path):\n",
    "    \"\"\"\n",
    "    Convert label data from JSON format to YOLO format.\n",
    "\n",
    "    Args:\n",
    "        json_path (str): Path to the JSON file containing the label information.\n",
    "        txt_output_path (str): Path to save the converted YOLO format label (.txt) file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    image_width = data['size']['width']\n",
    "    image_height = data['size']['height']\n",
    "\n",
    "    yolo_labels = []\n",
    "\n",
    "    for obj in data['objects']:\n",
    "        if obj['geometryType'] == 'rectangle':\n",
    "            class_id = 0  # Since we only have one class: smoke\n",
    "\n",
    "            # Extract the exterior points\n",
    "            x_min, y_min = obj['points']['exterior'][0]\n",
    "            x_max, y_max = obj['points']['exterior'][1]\n",
    "\n",
    "            # Convert to YOLO format (x_center, y_center, width, height)\n",
    "            x_center = (x_min + x_max) / 2 / image_width\n",
    "            y_center = (y_min + y_max) / 2 / image_height\n",
    "            width = (x_max - x_min) / image_width\n",
    "            height = (y_max - y_min) / image_height\n",
    "\n",
    "            yolo_labels.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "    # Write the labels to a .txt file\n",
    "    with open(txt_output_path, 'w') as txt_file:\n",
    "        for label in yolo_labels:\n",
    "            txt_file.write(label + '\\n')\n",
    "\n",
    "def NemoProcess2(nemo_path, output_path, test_split=0.1):\n",
    "    \"\"\"\n",
    "    Process the Nemo dataset into YOLO format with images and labels structured for train, val, and test sets.\n",
    "\n",
    "    Args:\n",
    "        nemo_path (str): Path to the root of the Nemo dataset.\n",
    "        output_path (str): Path where the YOLO formatted dataset will be stored.\n",
    "        test_split (float): Fraction of the data to use as a test set.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Define paths\n",
    "    train_img_path = os.path.join(nemo_path, 'train', 'img')\n",
    "    train_ann_path = os.path.join(nemo_path, 'train', 'ann')\n",
    "    val_img_path = os.path.join(nemo_path, 'val', 'img')\n",
    "    val_ann_path = os.path.join(nemo_path, 'val', 'ann')\n",
    "\n",
    "    # Create YOLO directory structure\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        os.makedirs(os.path.join(output_path, 'images', split), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_path, 'labels', split), exist_ok=True)\n",
    "\n",
    "    # Copy and split the dataset\n",
    "    def process_split(img_path, ann_path, split):\n",
    "        images = glob.glob(os.path.join(img_path, \"*.jpg\"))  # Assuming images are in .jpg format\n",
    "        labels = glob.glob(os.path.join(ann_path, \"*.json\"))\n",
    "\n",
    "        for img_file, json_file in zip(sorted(images), sorted(labels)):\n",
    "            img_name = os.path.basename(img_file)\n",
    "            txt_output_name = img_name.replace('.jpg', '.txt')\n",
    "            txt_output_path = os.path.join(output_path, 'labels', split, txt_output_name)\n",
    "\n",
    "            # Process the JSON label file\n",
    "            process_labels_nemo(json_file, txt_output_path)\n",
    "\n",
    "            shutil.copy(img_file, os.path.join(output_path, 'images', split, img_name))\n",
    "\n",
    "    # Process train and validation sets\n",
    "    process_split(train_img_path, train_ann_path, 'train')\n",
    "    process_split(val_img_path, val_ann_path, 'val')\n",
    "\n",
    "    # Optionally, move a portion of validation to the test set\n",
    "    train_images = os.listdir(os.path.join(output_path, 'images', 'train'))\n",
    "    train_labels = os.listdir(os.path.join(output_path, 'labels', 'train'))\n",
    "    \n",
    "    num_test = int(len(train_images) * test_split)\n",
    "    test_images = train_images[:num_test]\n",
    "    test_labels = train_labels[:num_test]\n",
    "    \n",
    "    for test_img, test_lbl in zip(test_images, test_labels):\n",
    "        shutil.move(os.path.join(output_path, 'images', 'train', test_img), os.path.join(output_path, 'images', 'test', test_img))\n",
    "        shutil.move(os.path.join(output_path, 'labels', 'train', test_lbl), os.path.join(output_path, 'labels', 'test', test_lbl))\n",
    "    # print len of train, val and test\n",
    "    print(f\"Train: {len(os.listdir(os.path.join(output_path, 'images', 'train')))}\")\n",
    "    print(f\"Val: {len(os.listdir(os.path.join(output_path, 'images', 'val')))}\")\n",
    "    print(f\"Test: {len(os.listdir(os.path.join(output_path, 'images', 'test')))}\")\n",
    "    print(f\"YOLO format dataset created at {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2416\n",
      "Val: 250\n",
      "Test: 268\n",
      "YOLO format dataset created at C:\\nico\\wildfire2024\\data\\NemoFixed\n"
     ]
    }
   ],
   "source": [
    "NemoProcess2(\n",
    "    nemo_path=r'C:\\nico\\wildfire2024\\data\\Nemo',\n",
    "    output_path=r'C:\\nico\\wildfire2024\\data\\NemoFixed',\n",
    "    test_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## figlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "\n",
    "def process_labels(json_path, txt_output_path):\n",
    "    \"\"\"\n",
    "    Convert label data from JSON format to YOLO format.\n",
    "\n",
    "    Args:\n",
    "        json_path (str): Path to the JSON file containing the label information.\n",
    "        txt_output_path (str): Path to save the converted YOLO format label (.txt) file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    image_width = data['size']['width']\n",
    "    image_height = data['size']['height']\n",
    "\n",
    "    yolo_labels = []\n",
    "\n",
    "    for obj in data['objects']:\n",
    "        if obj['geometryType'] == 'rectangle':\n",
    "            class_id = 0  # Since we only have one class: smoke\n",
    "\n",
    "            # Extract the exterior points\n",
    "            x_min, y_min = obj['points']['exterior'][0]\n",
    "            x_max, y_max = obj['points']['exterior'][1]\n",
    "\n",
    "            # Convert to YOLO format (x_center, y_center, width, height)\n",
    "            x_center = (x_min + x_max) / 2 / image_width\n",
    "            y_center = (y_min + y_max) / 2 / image_height\n",
    "            width = (x_max - x_min) / image_width\n",
    "            height = (y_max - y_min) / image_height\n",
    "\n",
    "            yolo_labels.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "    # Write the labels to a .txt file\n",
    "    with open(txt_output_path, 'w') as txt_file:\n",
    "        for label in yolo_labels:\n",
    "            txt_file.write(label + '\\n')\n",
    "\n",
    "def FigLibProcess(figlib_path, output_path, val_split=0.1, test_split=0.1):\n",
    "    \"\"\"\n",
    "    Process the FigLib dataset into YOLO format with images and labels structured for train, val, and test sets.\n",
    "\n",
    "    Args:\n",
    "        figlib_path (str): Path to the root of the FigLib dataset.\n",
    "        output_path (str): Path where the YOLO formatted dataset will be stored.\n",
    "        val_split (float): Fraction of the data to use as a validation set.\n",
    "        test_split (float): Fraction of the data to use as a test set.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Create YOLO directory structure\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        os.makedirs(os.path.join(output_path, 'images', split), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_path, 'labels', split), exist_ok=True)\n",
    "\n",
    "    # Gather all image-label pairs across all fire events\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "\n",
    "    for event_folder in os.listdir(figlib_path):\n",
    "        event_path = os.path.join(figlib_path, event_folder)\n",
    "        if os.path.isdir(event_path):\n",
    "            img_path = os.path.join(event_path, 'images')\n",
    "            ann_path = os.path.join(event_path, 'labels')\n",
    "\n",
    "            images = glob.glob(os.path.join(img_path, \"*.jpg\"))  # Assuming images are in .jpg format\n",
    "            labels = glob.glob(os.path.join(ann_path, \"*.txt\"))\n",
    "\n",
    "            all_images.extend(images)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    combined = list(zip(all_images, all_labels))\n",
    "    random.shuffle(combined)\n",
    "    all_images[:], all_labels[:] = zip(*combined)\n",
    "\n",
    "    # Split the dataset\n",
    "    num_total = len(all_images)\n",
    "    num_test = int(num_total * test_split)\n",
    "    num_val = int(num_total * val_split)\n",
    "\n",
    "    test_images = all_images[:num_test]\n",
    "    test_labels = all_labels[:num_test]\n",
    "\n",
    "    val_images = all_images[num_test:num_test + num_val]\n",
    "    val_labels = all_labels[num_test:num_test + num_val]\n",
    "\n",
    "    train_images = all_images[num_test + num_val:]\n",
    "    train_labels = all_labels[num_test + num_val:]\n",
    "\n",
    "    def process_split(images, labels, split):\n",
    "        for img_file, json_file in zip(images, labels):\n",
    "            img_name = os.path.basename(img_file)\n",
    "            txt_output_name = img_name.replace('.jpg', '.txt')\n",
    "            txt_output_path = os.path.join(output_path, 'labels', split, txt_output_name)\n",
    "\n",
    "            # Process the JSON label file\n",
    "            process_labels(json_file, txt_output_path)\n",
    "\n",
    "            shutil.copy(img_file, os.path.join(output_path, 'images', split, img_name))\n",
    "\n",
    "    # Process each split\n",
    "    process_split(train_images, train_labels, 'train')\n",
    "    process_split(val_images, val_labels, 'val')\n",
    "    process_split(test_images, test_labels, 'test')\n",
    "\n",
    "    print(f\"YOLO format dataset created at {output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "\n",
    "def FigLibProcess(figlib_path, output_path, val_split=0.1, test_split=0.1):\n",
    "    \"\"\"\n",
    "    Process the FigLib dataset into YOLO format with images and labels structured for train, val, and test sets.\n",
    "\n",
    "    Args:\n",
    "        figlib_path (str): Path to the root of the FigLib dataset.\n",
    "        output_path (str): Path where the YOLO formatted dataset will be stored.\n",
    "        val_split (float): Fraction of the data to use as a validation set.\n",
    "        test_split (float): Fraction of the data to use as a test set.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Create YOLO directory structure\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        os.makedirs(os.path.join(output_path, 'images', split), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_path, 'labels', split), exist_ok=True)\n",
    "\n",
    "    # Gather all image-label pairs across all fire events\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "\n",
    "    for event_folder in os.listdir(figlib_path):\n",
    "        event_path = os.path.join(figlib_path, event_folder)\n",
    "        if os.path.isdir(event_path):\n",
    "            # img_path = os.path.join(event_path, 'images')\n",
    "            ann_path = os.path.join(event_path, 'labels')\n",
    "\n",
    "            images = glob.glob(os.path.join(event_path, \"*.jpg\"))  # Assuming images are in .jpg format\n",
    "            labels = glob.glob(os.path.join(ann_path, \"*.txt\"))  # Assuming labels are in .txt format\n",
    "\n",
    "            all_images.extend(images)\n",
    "            all_labels.extend(labels)\n",
    "    print(f\"Total images: {len(all_images)}\")\n",
    "    print(f\"Total labels: {len(all_labels)}\")\n",
    "    # Shuffle the dataset\n",
    "    combined = list(zip(all_images, all_labels))\n",
    "    random.shuffle(combined)\n",
    "    all_images[:], all_labels[:] = zip(*combined)\n",
    "\n",
    "    # Split the dataset\n",
    "    num_total = len(all_images)\n",
    "    num_test = int(num_total * test_split)\n",
    "    num_val = int(num_total * val_split)\n",
    "\n",
    "    test_images = all_images[:num_test]\n",
    "    test_labels = all_labels[:num_test]\n",
    "\n",
    "    val_images = all_images[num_test:num_test + num_val]\n",
    "    val_labels = all_labels[num_test:num_test + num_val]\n",
    "\n",
    "    train_images = all_images[num_test + num_val:]\n",
    "    train_labels = all_labels[num_test + num_val:]\n",
    "\n",
    "    def process_split(images, labels, split):\n",
    "        for img_file, label_file in zip(images, labels):\n",
    "            img_name = os.path.basename(img_file)\n",
    "            label_name = os.path.basename(label_file)\n",
    "\n",
    "            shutil.copy(img_file, os.path.join(output_path, 'images', split, img_name))\n",
    "            shutil.copy(label_file, os.path.join(output_path, 'labels', split, label_name))\n",
    "\n",
    "    # Process each split\n",
    "    process_split(train_images, train_labels, 'train')\n",
    "    process_split(val_images, val_labels, 'val')\n",
    "    process_split(test_images, test_labels, 'test')\n",
    "\n",
    "    print(f\"YOLO format dataset created at {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 24758\n",
      "Total labels: 24758\n",
      "YOLO format dataset created at C:\\nico\\wildfire2024\\data\\testfig\n"
     ]
    }
   ],
   "source": [
    "figlib_path = r\"C:\\nico\\wildfire2024\\data\\Fig_Lib\\FIGLIB_ANNOTATED_RESIZED\"  # Path to the root of the extracted FigLib dataset\n",
    "output_path = r\"C:\\nico\\wildfire2024\\data\\testfig\"  # Path where you want to store the YOLO formatted dataset\n",
    "\n",
    "FigLibProcess(figlib_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS-71c1fd51-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def create_test_split_with_copy(dataset_path, new_dataset_path, test_split=0.1):\n",
    "    \"\"\"\n",
    "    Create a test split by copying the entire dataset to a new location,\n",
    "    then moving a portion of the train set to a new test set. Also, create\n",
    "    empty .txt files for images that lack corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to the original dataset with 'train' and 'val' directories.\n",
    "        new_dataset_path (str): Path to the new dataset location.\n",
    "        test_split (float): Fraction of the train set to use as a test set.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy the entire dataset to a new location\n",
    "    if os.path.exists(new_dataset_path):\n",
    "        print(f\"Removing existing directory at {new_dataset_path}\")\n",
    "        shutil.rmtree(new_dataset_path)\n",
    "    shutil.copytree(dataset_path, new_dataset_path)\n",
    "    print(f\"Copied dataset from {dataset_path} to {new_dataset_path}\")\n",
    "\n",
    "    # Define paths in the new dataset\n",
    "    train_img_path = os.path.join(new_dataset_path, 'images', 'train')\n",
    "    train_label_path = os.path.join(new_dataset_path, 'labels', 'train')\n",
    "\n",
    "    val_img_path = os.path.join(new_dataset_path, 'images', 'val')\n",
    "    val_label_path = os.path.join(new_dataset_path, 'labels', 'val')\n",
    "\n",
    "    test_img_path = os.path.join(new_dataset_path, 'images', 'test')\n",
    "    test_label_path = os.path.join(new_dataset_path, 'labels', 'test')\n",
    "\n",
    "    # Create test directories if they don't exist\n",
    "    os.makedirs(test_img_path, exist_ok=True)\n",
    "    os.makedirs(test_label_path, exist_ok=True)\n",
    "\n",
    "    # Ensure all images have corresponding labels\n",
    "    def ensure_labels_exist(image_dir, label_dir):\n",
    "        images = sorted(os.listdir(image_dir))\n",
    "        labels = set(os.listdir(label_dir))\n",
    "\n",
    "        for img_name in images:\n",
    "            label_name = img_name.replace('.jpg', '.txt')  # Assuming the images are in .jpg format\n",
    "            if label_name not in labels:\n",
    "                # Create an empty label file if it doesn't exist\n",
    "                open(os.path.join(label_dir, label_name), 'w').close()\n",
    "\n",
    "    # Ensure labels exist in train and val sets\n",
    "    ensure_labels_exist(train_img_path, train_label_path)\n",
    "    ensure_labels_exist(val_img_path, val_label_path)\n",
    "\n",
    "    # List all images and corresponding labels\n",
    "    train_images = sorted(os.listdir(train_img_path))\n",
    "    train_labels = sorted(os.listdir(train_label_path))\n",
    "\n",
    "    # Shuffle and split the dataset\n",
    "    combined = list(zip(train_images, train_labels))\n",
    "    random.shuffle(combined)\n",
    "    train_images[:], train_labels[:] = zip(*combined)\n",
    "\n",
    "    num_test = int(len(train_images) * test_split)\n",
    "\n",
    "    test_images = train_images[:num_test]\n",
    "    test_labels = train_labels[:num_test]\n",
    "\n",
    "    # Move the selected images and labels to the test set\n",
    "    for img_name, label_name in zip(test_images, test_labels):\n",
    "        shutil.move(os.path.join(train_img_path, img_name), os.path.join(test_img_path, img_name))\n",
    "        shutil.move(os.path.join(train_label_path, label_name), os.path.join(test_label_path, label_name))\n",
    "\n",
    "    print(f\"Moved {num_test} images and labels to the test set.\")\n",
    "\n",
    "    # Ensure labels exist in the test set\n",
    "    ensure_labels_exist(test_img_path, test_label_path)\n",
    "\n",
    "    print(f\"Completed creating the test set and ensuring all images have labels.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied dataset from C:\\nico\\wildfire2024\\data\\DS-71c1fd51-v2 to C:\\nico\\wildfire2024\\data\\DS-71c1fd51-v2-Fixed\n",
      "Moved 670 images and labels to the test set.\n",
      "Completed creating the test set and ensuring all images have labels.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = r\"C:\\nico\\wildfire2024\\data\\DS-71c1fd51-v2\"  # Path to the original dataset\n",
    "new_dataset_path = r\"C:\\nico\\wildfire2024\\data\\DS-71c1fd51-v2-Fixed\"  # Path to the new dataset copy\n",
    "\n",
    "create_test_split_with_copy(dataset_path, new_dataset_path, test_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
